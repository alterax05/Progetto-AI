{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modello AI per Quick Draw doodle recognition\n",
        "Per installare le dipendenze necessarie definite in requirements.txt\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "oppure\n",
        "```bash\n",
        "pip install torch torch torchvision onnx requests\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WMw65hcGEvr9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: torchvision in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.2)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
            "Requirement already satisfied: onnx in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.15.0)\n",
            "Requirement already satisfied: requests in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: progressbar in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5)\n",
            "Requirement already satisfied: filelock in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.12.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx) (4.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mikyp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install torch torchvision torchaudio onnx requests progressbar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch import cuda\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from typing import List, Optional\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import math\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Imposto il device su GPU se disponibile\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Funzione per ottenere tutti i nomi delle classi di quickdraw (non usata)\n",
        "def get_all_quickdraw_class_names():\n",
        "    url = \"https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt\"\n",
        "    r = requests.get(url)\n",
        "    classes: List = [x.replace(' ', '_') for x in r.text.splitlines()]\n",
        "    return classes\n",
        "\n",
        "#Lista limitata di classi di quickdraw\n",
        "def get_quickdraw_class_names():\n",
        "    classes: List = [\"airplane\",\"ambulance\",\"apple\",\"asparagus\",\"banana\",\"baseball\",\"basketball\",\"birthday_cake\",\"The_Eiffel_Tower\",\"The_Mona_Lisa\",\"triangle\",\"t-shirt\"]\n",
        "    return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download del dataset di quickdraw da google storage bucket\n",
        "def download_quickdraw_dataset(root=\"./dataset\", limit: Optional[int] = None, class_names: List[str]=None, select_all:bool =False):\n",
        "    if class_names is None:\n",
        "        class_names = get_quickdraw_class_names()\n",
        "    if select_all:\n",
        "        class_names = get_all_quickdraw_class_names()\n",
        "\n",
        "    root = Path(root)\n",
        "    root.mkdir(exist_ok=True, parents=True)\n",
        "    url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "\n",
        "    print(\"Downloading Quickdraw Dataset...\")\n",
        "    for class_name in class_names[:limit]:\n",
        "        fpath = root / f\"{class_name}.npy\"\n",
        "        if not fpath.exists():\n",
        "            urllib.request.urlretrieve(f\"{url}{class_name.replace('_', '%20')}.npy\", fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_quickdraw_data(root=\"./dataset\", max_items_per_class=5000):\n",
        "    all_files = Path(root).glob('*.npy')\n",
        "\n",
        "    x = np.empty([0, 784], dtype=np.uint8) #Data\n",
        "    y = np.empty([0], dtype=np.longlong) #Labels\n",
        "    class_names = [] #Nomi delle classi\n",
        "\n",
        "    print(f\"Loading {max_items_per_class} examples for each class from the Quickdraw Dataset...\")\n",
        "    \n",
        "    for idx, file in enumerate(sorted(all_files)):\n",
        "        #Carica i dati da ogni file\n",
        "        data = np.load(file, mmap_mode='r')\n",
        "        #Tronca i dati a max_items_per_class\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        #Aggiunge i dati e le labels\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "        class_names.append(file.stem)\n",
        "\n",
        "    return x, y, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qaviYKSbE3Pu"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Dataset di quickdraw per pytorch ereditando da torch.utils.data.Dataset\n",
        "class QuickDrawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, max_items_per_class=5000, class_limit=None):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.max_items_per_class = max_items_per_class\n",
        "        self.class_limit = class_limit\n",
        "\n",
        "        download_quickdraw_dataset(self.root, self.class_limit)\n",
        "        self.X, self.Y, self.classes = load_quickdraw_data(self.root, self.max_items_per_class)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = (self.X[idx] / 255.).astype(np.float32).reshape(1, 28, 28)\n",
        "        y = self.Y[idx]\n",
        "\n",
        "        return torch.from_numpy(x), y.item()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        x = torch.stack([item[0] for item in batch])\n",
        "        y = torch.LongTensor([item[1] for item in batch])\n",
        "        return {'pixel_values': x, 'labels': y}\n",
        "    \n",
        "    def split(self, pct=0.1):\n",
        "        num_classes = len(self.classes)\n",
        "        indices = torch.randperm(len(self)).tolist()\n",
        "        n_val = math.floor(len(indices) * pct)\n",
        "        train_ds = torch.utils.data.Subset(self, indices[:-n_val])\n",
        "        val_ds = torch.utils.data.Subset(self, indices[-n_val:])\n",
        "        return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "L_tgy3PyFBpN",
        "outputId": "4ffc322c-2388-4945-e960-dfdcf2392318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Quickdraw Dataset...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m max_examples_per_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20000\u001b[39m\n\u001b[0;32m      3\u001b[0m train_val_split_pct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.1\u001b[39m\n\u001b[1;32m----> 5\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mQuickDrawDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_examples_per_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ds\u001b[38;5;241m.\u001b[39mclasses)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[24], line 9\u001b[0m, in \u001b[0;36mQuickDrawDataset.__init__\u001b[1;34m(self, root, max_items_per_class, class_limit)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_items_per_class \u001b[38;5;241m=\u001b[39m max_items_per_class\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_limit \u001b[38;5;241m=\u001b[39m class_limit\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdownload_quickdraw_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses \u001b[38;5;241m=\u001b[39m load_quickdraw_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_items_per_class)\n",
            "Cell \u001b[1;32mIn[22], line 16\u001b[0m, in \u001b[0;36mdownload_quickdraw_dataset\u001b[1;34m(root, limit, class_names, select_all)\u001b[0m\n\u001b[0;32m     14\u001b[0m fpath \u001b[38;5;241m=\u001b[39m root \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fpath\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m---> 16\u001b[0m     \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43murl\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mclass_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m20\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\mikyp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m block:\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mikyp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mc:\\Users\\mikyp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\mikyp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mc:\\Users\\mikyp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "data_dir = './dataset'\n",
        "max_examples_per_class = 20000\n",
        "train_val_split_pct = .1\n",
        "\n",
        "ds = QuickDrawDataset(data_dir, max_examples_per_class)\n",
        "num_classes = len(ds.classes)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "#Dataset di training e di validazione\n",
        "train_ds, val_ds = ds.split(train_val_split_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpRtWkeH_lG5"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDuedQdSJF9z"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      2\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      3\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      4\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m      7\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      8\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     10\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2304\u001b[39m, \u001b[38;5;241m512\u001b[39m),\n\u001b[0;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m---> 14\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[43mnum_classes\u001b[49m),\n\u001b[0;32m     15\u001b[0m )\n",
            "\u001b[1;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ],
      "source": [
        "class Model(nn.Module):\n",
        "    #Constuttore\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = Model().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> 2\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m Adam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funzione di valutare il modello con dati che non ha mai visto\n",
        "def evaluate(model):\n",
        "    correct = 0\n",
        "    for data, target in DataLoader(val_ds, batch_size=64):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        pred = model(data)\n",
        "        correct += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
        "    print(f'Accuracy: {(correct/num_classes)*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fuzione per esportare il modello in formato ONNX\n",
        "def toONNX(model, filename):\n",
        "    #                        (batch, channel, width and height)\n",
        "    dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "    torch.onnx.export(model, dummy_input, filename, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4pzdmBK_mvt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "7A9iOabpFJ6u",
        "outputId": "2f69c6d0-f45c-48eb-fed3-688992f46b04"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    for epoch in range(20):\n",
        "        for idx_batch, (x,y) in enumerate(DataLoader(val_ds, batch_size=64)):\n",
        "            y_hat = model(x)\n",
        "\n",
        "            loss = loss_fn(y_hat, y)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            print(loss.item())\n",
        "    \n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    print('Done training')\n",
        "\n",
        "    evaluate(model)\n",
        "\n",
        "    toONNX(model, 'model.onnx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMbD9KilU/oVAeLMDVOC9Ye",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "quickdraw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
