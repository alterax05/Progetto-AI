{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e0sVPDuxB0-"
      },
      "source": [
        "# Modello AI per Quick, Draw! doodle recognition\n",
        "Per installare le dipendenze necessarie definite in requirements.txt\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "oppure\n",
        "```bash\n",
        "pip install torch torch torchvision onnx requests\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMw65hcGEvr9"
      },
      "outputs": [],
      "source": [
        "! pip install torch torchvision torchaudio onnx requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eiRpeJpRxB1I"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch import cuda\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from typing import List, Optional\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t_lW2MFdxB1J"
      },
      "outputs": [],
      "source": [
        "#Imposto il device su GPU se disponibile\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oFOniv03xB1K"
      },
      "outputs": [],
      "source": [
        "#Funzione per ottenere tutti i nomi delle classi di quickdraw (non usata)\n",
        "def get_all_quickdraw_class_names():\n",
        "    url = \"https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt\"\n",
        "    r = requests.get(url)\n",
        "    classes: List = [x.replace(' ', '_') for x in r.text.splitlines()]\n",
        "    return classes\n",
        "\n",
        "#Lista limitata di classi di quickdraw\n",
        "def get_quickdraw_class_names():\n",
        "    classes = ['The Eiffel Tower','tent','airplane','ambulance','apple','asparagus','banana','baseball','basketball','birthday cake','t-shirt','triangle','elephant','guitar','rainbow','lighthouse','television','snowman','penguin','coffee cup']\n",
        "    classes = sorted([x.replace(' ', '_') for x in classes])\n",
        "    return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mWkZCpIYxB1L"
      },
      "outputs": [],
      "source": [
        "# Download del dataset di quickdraw da google storage bucket\n",
        "def download_quickdraw_dataset(root=\"./dataset\", limit: Optional[int] = None, class_names: List[str]=None, select_all:bool =False):\n",
        "    if class_names is None:\n",
        "        class_names = get_quickdraw_class_names()\n",
        "    if select_all:\n",
        "        class_names = get_all_quickdraw_class_names()\n",
        "\n",
        "    root = Path(root)\n",
        "    root.mkdir(exist_ok=True, parents=True)\n",
        "    url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "\n",
        "    print(\"Downloading Quickdraw Dataset...\")\n",
        "    for class_name in class_names[:limit]:\n",
        "        fpath = root / f\"{class_name}.npy\"\n",
        "        if not fpath.exists():\n",
        "            print(class_name)\n",
        "            urllib.request.urlretrieve(f\"{url}{class_name.replace('_', '%20')}.npy\", fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cSgMfpiqxB1M"
      },
      "outputs": [],
      "source": [
        "def load_quickdraw_data(root=\"./dataset\", max_items_per_class=5000):\n",
        "    all_files = Path(root).glob('*.npy')\n",
        "\n",
        "    x = np.empty([0, 784], dtype=np.uint8) #Data\n",
        "    y = np.empty([0], dtype=np.longlong) #Labels\n",
        "    class_names = [] #Nomi delle classi\n",
        "\n",
        "    print(f\"Loading {max_items_per_class} examples for each class from the Quickdraw Dataset...\")\n",
        "\n",
        "    for idx, file in enumerate(sorted(all_files)):\n",
        "        #Carica i dati da ogni file\n",
        "        data = np.load(file, mmap_mode='r')\n",
        "        #Tronca i dati a max_items_per_class\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        #Aggiunge i dati e le labels\n",
        "        #I dati sono salvati come array NumPy\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "        class_names.append(file.stem)\n",
        "\n",
        "    return x, y, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qaviYKSbE3Pu"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Dataset di quickdraw per pytorch ereditando da torch.utils.data.Dataset\n",
        "class QuickDrawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, max_items_per_class=5000, class_limit=None, transform=None):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.max_items_per_class = max_items_per_class\n",
        "        self.class_limit = class_limit\n",
        "        self.transform = transform\n",
        "        download_quickdraw_dataset(self.root, self.class_limit)\n",
        "        self.X, self.Y, self.classes = load_quickdraw_data(self.root, self.max_items_per_class)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = (self.X[idx] / 255.).astype(np.float32).reshape(1, 28, 28)\n",
        "        y = self.Y[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(x)\n",
        "\n",
        "        return torch.from_numpy(x), y.item()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        x = torch.stack([item[0] for item in batch])\n",
        "        y = torch.LongTensor([item[1] for item in batch])\n",
        "        return {'pixel_values': x, 'labels': y}\n",
        "\n",
        "    def split(self, pct=0.1):\n",
        "        num_classes = len(self.classes)\n",
        "        indices = torch.randperm(len(self)).tolist()\n",
        "        n_val = math.floor(len(indices) * pct)\n",
        "        train_ds = torch.utils.data.Subset(self, indices[:-n_val])\n",
        "        noTransform = self\n",
        "        noTransform.transform = None\n",
        "        val_ds = torch.utils.data.Subset(noTransform, indices[-n_val:])\n",
        "        return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_tgy3PyFBpN"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_dir = './dataset'\n",
        "max_examples_per_class = 20000\n",
        "train_val_split_pct = .1\n",
        "\n",
        "#Trasformazioni da applicare al dataset\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(28),\n",
        "])\n",
        "\n",
        "ds = QuickDrawDataset(data_dir, max_examples_per_class, transform=data_transforms)\n",
        "num_classes = len(ds.classes)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "#Dataset di training e di validazione\n",
        "train_ds, val_ds = ds.split(train_val_split_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpRtWkeH_lG5"
      },
      "source": [
        "## Layer Max Polling\n",
        "A differenza del modello precedentemente descritto, questo oltre che alle funzioni di attivazione e a i layer convoluzionali possiede anche dei layer di MaxPolling.\n",
        "Il Max Pooling è una tecnica utilizzata nei modelli di deep learning per ridurre le dimensioni spaziali (larghezza e altezza) di un tensore 3D. Ciò viene fatto per ridurre la potenza di calcolo necessaria per elaborare i dati attraverso la riduzione della dimensionalità. Inoltre, aiuta a estrarre le caratteristiche dominanti dalla mappa delle caratteristiche di input, rendendo il modello più flessibile a lievi cambiamenti e variazioni nell'immagine.\n",
        "Il processo prevede lo scorrimento di una finestra (nota anche come kernel) sulla mappa delle caratteristiche di input. In ogni finestra, il valore massimo viene preso e utilizzato per formare una nuova mappa di caratteristiche di dimensioni ridotte. Questa operazione viene in genere applicata dopo uno strato convoluzionale, che viene utilizzato per estrarre le caratteristiche dall'immagine di ingresso.\n",
        "L'invarianza alla traslazione significa che se l'immagine viene leggermente spostata, l'output dell'operazione Max Pooling non cambia in modo significativo. Questo perché prende il valore massimo in una finestra, quindi un piccolo spostamento probabilmente includerà lo stesso valore massimo in una nuova finestra. Questa proprietà aiuta il modello a riconoscere gli oggetti in un'immagine indipendentemente dalla loro posizione nell'immagine.\n",
        "![Max pooling](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png \"Max pooling\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IDuedQdSJF9z"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    #Constuttore\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = Model().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7WGrchO7xB1S"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "klhTEZQvxB1S"
      },
      "outputs": [],
      "source": [
        "# Funzione di valutare il modello con dati che non ha mai visto\n",
        "def evaluate(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, target in DataLoader(val_ds, batch_size=64):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        pred = model(data)\n",
        "        correct += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
        "        total += target.size(0)\n",
        "    print(f'Accuracy: {(correct/total)*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DszwXRuWxB1T"
      },
      "outputs": [],
      "source": [
        "# Fuzione per esportare il modello in formato ONNX\n",
        "def toONNX(model, filename):\n",
        "    #                        (batch, channel, width and height)\n",
        "    dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "    torch.onnx.export(model, dummy_input, filename, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4pzdmBK_mvt"
      },
      "source": [
        "# Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A9iOabpFJ6u",
        "outputId": "d6621813-d3b5-41b5-e19d-2ea3e0e358ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 2.994576930999756\n",
            "Epoch: 0, Loss: 0.2045162320137024\n",
            "Epoch: 1, Loss: 0.20811180770397186\n",
            "Epoch: 1, Loss: 0.1384311318397522\n",
            "Epoch: 2, Loss: 0.17628565430641174\n",
            "Epoch: 2, Loss: 0.12337444722652435\n",
            "Epoch: 3, Loss: 0.14479699730873108\n",
            "Epoch: 3, Loss: 0.12609733641147614\n",
            "Epoch: 4, Loss: 0.14542172849178314\n",
            "Epoch: 4, Loss: 0.06377806514501572\n",
            "Epoch: 5, Loss: 0.0996314063668251\n",
            "Epoch: 5, Loss: 0.1065841019153595\n",
            "Epoch: 6, Loss: 0.09160200506448746\n",
            "Epoch: 6, Loss: 0.0704256221652031\n",
            "Epoch: 7, Loss: 0.0993790477514267\n",
            "Epoch: 7, Loss: 0.015464884229004383\n",
            "Epoch: 8, Loss: 0.05389177054166794\n",
            "Epoch: 8, Loss: 0.016437966376543045\n",
            "Epoch: 9, Loss: 0.08093626797199249\n",
            "Epoch: 9, Loss: 0.012937980704009533\n",
            "Epoch: 10, Loss: 0.12692204117774963\n",
            "Epoch: 10, Loss: 0.206926628947258\n",
            "Epoch: 11, Loss: 0.03833181783556938\n",
            "Epoch: 11, Loss: 0.05831775814294815\n",
            "Epoch: 12, Loss: 0.016750497743487358\n",
            "Epoch: 12, Loss: 0.05658635497093201\n",
            "Epoch: 13, Loss: 0.04391051083803177\n",
            "Epoch: 13, Loss: 0.0016770079964771867\n",
            "Epoch: 14, Loss: 0.00796413328498602\n",
            "Epoch: 14, Loss: 0.11041872948408127\n",
            "Done training\n",
            "Accuracy: 92.75999999999999%\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    for epoch in range(15): \n",
        "        for idx_batch, (data,target) in enumerate(DataLoader(train_ds, batch_size=64)):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # Stampa cosa viene classificato\n",
        "            # print(get_quickdraw_class_names()[target[1]])\n",
        "            # display(transforms.functional.to_pil_image(data[1]))\n",
        "\n",
        "            y_hat = model(data).to(device)\n",
        "            loss = loss_fn(y_hat, target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if idx_batch % 3000 == 0:\n",
        "                print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    print('Done training')\n",
        "\n",
        "    evaluate(model)\n",
        "\n",
        "    toONNX(model, 'model.onnx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "quickdraw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
