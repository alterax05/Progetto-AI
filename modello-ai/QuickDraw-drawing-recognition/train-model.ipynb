{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modello AI per Quick Draw doodle recognition\n",
        "Per installare le dipendenze necessarie definite in requirements.txt\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "oppure\n",
        "```bash\n",
        "pip install torch torch torchvision onnx requests\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMw65hcGEvr9"
      },
      "outputs": [],
      "source": [
        "! pip install torch torchvision torchaudio onnx requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch import cuda\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from typing import List, Optional\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Imposto il device su GPU se disponibile\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Funzione per ottenere tutti i nomi delle classi di quickdraw (non usata)\n",
        "def get_all_quickdraw_class_names():\n",
        "    url = \"https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt\"\n",
        "    r = requests.get(url)\n",
        "    classes: List = [x.replace(' ', '_') for x in r.text.splitlines()]\n",
        "    return classes\n",
        "\n",
        "#Lista limitata di classi di quickdraw\n",
        "def get_quickdraw_class_names():\n",
        "    classes = ['Eiffel Tower','Tent','Airplane','Ambulance','Apple','Asparagus','Banana','Baseball','Basketball','Birthday Cake','T-shirt','Triangle','Elephant','Guitar','Rainbow','Lighthouse','Television','Snowman','Penguin','Coffee Cup']\n",
        "    classes = sorted([x.replace(' ', '_').lower() for x in classes])\n",
        "    return classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download del dataset di quickdraw da google storage bucket\n",
        "def download_quickdraw_dataset(root=\"./dataset\", limit: Optional[int] = None, class_names: List[str]=None, select_all:bool =False):\n",
        "    if class_names is None:\n",
        "        class_names = get_quickdraw_class_names()\n",
        "    if select_all:\n",
        "        class_names = get_all_quickdraw_class_names()\n",
        "\n",
        "    root = Path(root)\n",
        "    root.mkdir(exist_ok=True, parents=True)\n",
        "    url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "\n",
        "    print(\"Downloading Quickdraw Dataset...\")\n",
        "    for class_name in class_names[:limit]:\n",
        "        fpath = root / f\"{class_name}.npy\"\n",
        "        if not fpath.exists():\n",
        "            urllib.request.urlretrieve(f\"{url}{class_name.replace('_', '%20')}.npy\", fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_quickdraw_data(root=\"./dataset\", max_items_per_class=5000):\n",
        "    all_files = Path(root).glob('*.npy')\n",
        "\n",
        "    x = np.empty([0, 784], dtype=np.uint8) #Data\n",
        "    y = np.empty([0], dtype=np.longlong) #Labels\n",
        "    class_names = [] #Nomi delle classi\n",
        "\n",
        "    print(f\"Loading {max_items_per_class} examples for each class from the Quickdraw Dataset...\")\n",
        "    \n",
        "    for idx, file in enumerate(sorted(all_files)):\n",
        "        #Carica i dati da ogni file\n",
        "        data = np.load(file, mmap_mode='r')\n",
        "        #Tronca i dati a max_items_per_class\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        #Aggiunge i dati e le labels\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "        class_names.append(file.stem)\n",
        "\n",
        "    return x, y, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaviYKSbE3Pu"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Dataset di quickdraw per pytorch ereditando da torch.utils.data.Dataset\n",
        "class QuickDrawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, max_items_per_class=5000, class_limit=None, transform=None):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.max_items_per_class = max_items_per_class\n",
        "        self.class_limit = class_limit\n",
        "        self.transform = transform\n",
        "        download_quickdraw_dataset(self.root, self.class_limit)\n",
        "        self.X, self.Y, self.classes = load_quickdraw_data(self.root, self.max_items_per_class)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = (self.X[idx] / 255.).astype(np.float32).reshape(1, 28, 28)\n",
        "        y = self.Y[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(x)\n",
        "\n",
        "        return torch.from_numpy(x), y.item()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        x = torch.stack([item[0] for item in batch])\n",
        "        y = torch.LongTensor([item[1] for item in batch])\n",
        "        return {'pixel_values': x, 'labels': y}\n",
        "    \n",
        "    def split(self, pct=0.1):\n",
        "        num_classes = len(self.classes)\n",
        "        indices = torch.randperm(len(self)).tolist()\n",
        "        n_val = math.floor(len(indices) * pct)\n",
        "        train_ds = torch.utils.data.Subset(self, indices[:-n_val])\n",
        "        noTransform = self\n",
        "        noTransform.transform = None\n",
        "        val_ds = torch.utils.data.Subset(noTransform, indices[-n_val:])\n",
        "        return train_ds, val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "L_tgy3PyFBpN",
        "outputId": "4ffc322c-2388-4945-e960-dfdcf2392318"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_dir = './dataset'\n",
        "max_examples_per_class = 20000\n",
        "train_val_split_pct = .1\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(28),  # assuming input images are of size 224x224\n",
        "])\n",
        "\n",
        "ds = QuickDrawDataset(data_dir, max_examples_per_class, transform=data_transforms)\n",
        "num_classes = len(ds.classes)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "#Dataset di training e di validazione\n",
        "train_ds, val_ds = ds.split(train_val_split_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpRtWkeH_lG5"
      },
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDuedQdSJF9z"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    #Constuttore\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding='same'),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2304, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = Model().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funzione di valutare il modello con dati che non ha mai visto\n",
        "def evaluate(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data, target in DataLoader(val_ds, batch_size=64):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        pred = model(data)\n",
        "        correct += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
        "        total += target.size(0)\n",
        "    print(f'Accuracy: {(correct/total)*100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fuzione per esportare il modello in formato ONNX\n",
        "def toONNX(model, filename):\n",
        "    #                        (batch, channel, width and height)\n",
        "    dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "    torch.onnx.export(model, dummy_input, filename, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4pzdmBK_mvt"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "7A9iOabpFJ6u",
        "outputId": "2f69c6d0-f45c-48eb-fed3-688992f46b04"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    for epoch in range(15):\n",
        "        for idx_batch, (data,target) in enumerate(DataLoader(train_ds, batch_size=64)):\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # Stampa cosa viene classificato\n",
        "            # print(get_quickdraw_class_names()[target[1]])\n",
        "            # display(transforms.functional.to_pil_image(data[1]))\n",
        "\n",
        "            y_hat = model(data).to(device)\n",
        "            loss = loss_fn(y_hat, target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if idx_batch % 3000 == 0:\n",
        "                print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    torch.save(model.state_dict(), 'model.pth')\n",
        "\n",
        "    print('Done training')\n",
        "\n",
        "    evaluate(model)\n",
        "\n",
        "    toONNX(model, 'model.onnx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMbD9KilU/oVAeLMDVOC9Ye",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "quickdraw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
